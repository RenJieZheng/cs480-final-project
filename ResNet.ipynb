{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":81655,"databundleVersionId":8915386,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.metrics import r2_score\n\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\nfrom torchvision.models import resnet50, ResNet50_Weights, resnet34, ResNet34_Weights, inception_v3, Inception_V3_Weights","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-10T16:18:57.700458Z","iopub.execute_input":"2024-08-10T16:18:57.700722Z","iopub.status.idle":"2024-08-10T16:19:05.899985Z","shell.execute_reply.started":"2024-08-10T16:18:57.700697Z","shell.execute_reply":"2024-08-10T16:19:05.898954Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"'''for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))'''\n\n'''from PIL import Image\n\nimage1 = Image.open(\"/kaggle/input/cs-480-2024-spring/data/train_images/190966811.jpeg\")\nimage2 = Image.open(\"/kaggle/input/cs-480-2024-spring/data/test_images/179127153.jpeg\")\n\nprint(image1.mode)\nprint(image1.size)\nprint(image2.mode)\nprint(image2.size)'''","metadata":{"execution":{"iopub.status.busy":"2024-08-10T16:19:05.901707Z","iopub.execute_input":"2024-08-10T16:19:05.902316Z","iopub.status.idle":"2024-08-10T16:19:05.909614Z","shell.execute_reply.started":"2024-08-10T16:19:05.902271Z","shell.execute_reply":"2024-08-10T16:19:05.908684Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'from PIL import Image\\n\\nimage1 = Image.open(\"/kaggle/input/cs-480-2024-spring/data/train_images/190966811.jpeg\")\\nimage2 = Image.open(\"/kaggle/input/cs-480-2024-spring/data/test_images/179127153.jpeg\")\\n\\nprint(image1.mode)\\nprint(image1.size)\\nprint(image2.mode)\\nprint(image2.size)'"},"metadata":{}}]},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/cs-480-2024-spring/data/train.csv\")\ntrain_data = train_data.set_index('id')\nvalidation_data = train_data.sample(frac = 0.1)\ntrain_data =  train_data.drop(validation_data.index)\n\ntrain_traits = train_data.iloc[:,-6:]\ntrain_data = train_data.iloc[:,:-6]\n\nvalidation_traits = validation_data.iloc[:,-6:]\nvalidation_data = validation_data.iloc[:,:-6]","metadata":{"execution":{"iopub.status.busy":"2024-08-10T16:19:05.910730Z","iopub.execute_input":"2024-08-10T16:19:05.910994Z","iopub.status.idle":"2024-08-10T16:19:07.744622Z","shell.execute_reply.started":"2024-08-10T16:19:05.910972Z","shell.execute_reply":"2024-08-10T16:19:07.743794Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"'''print(len(train_data), len(validation_data))\nprint(train_traits.head())\nprint(validation_traits.head())'''","metadata":{"execution":{"iopub.status.busy":"2024-08-10T16:19:07.746585Z","iopub.execute_input":"2024-08-10T16:19:07.746917Z","iopub.status.idle":"2024-08-10T16:19:07.752428Z","shell.execute_reply.started":"2024-08-10T16:19:07.746891Z","shell.execute_reply":"2024-08-10T16:19:07.751517Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'print(len(train_data), len(validation_data))\\nprint(train_traits.head())\\nprint(validation_traits.head())'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data transformation","metadata":{}},{"cell_type":"code","source":"# Log \ntrain_traits_log = np.log10(train_traits)\nvalidation_traits_log = np.log10(validation_traits)\n\n# Values\ntraits_max = train_traits_log.max()\ntraits_min = train_traits_log.min()\ntraits_mean = train_traits.mean()\ntraits_std = train_traits.std()\n\ndata_max = train_data.max()\ndata_min = train_data.min()\ndata_mean = train_data.mean()\ndata_std = train_data.std()\n\n# Normalize\ntrain_traits_normalized = (train_traits_log - traits_min) / (traits_max - traits_min)\nvalidation_traits_normalized = (validation_traits_log - traits_min) / (traits_max - traits_min)\n\ntrain_data_normalized = (train_data - data_min) / (data_max - data_min)\nvalidation_data_normalized = (validation_data - data_min) / (data_max - data_min)\n\ndef inverse_transformation(trait):\n    return np.power(10, (trait * (traits_max - traits_min)) + traits_min)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T16:19:07.753462Z","iopub.execute_input":"2024-08-10T16:19:07.753729Z","iopub.status.idle":"2024-08-10T16:19:07.872103Z","shell.execute_reply.started":"2024-08-10T16:19:07.753706Z","shell.execute_reply":"2024-08-10T16:19:07.871118Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"'''print(train_traits_normalized.head())\nprint(validation_traits_normalized.head())\nprint(train_data_normalized.head())\nprint(validation_data_normalized.head())'''\n\n'''\nprint(test_data.head())\nprint(test_traits.head())'''\n\n'''print(train_traits.loc[101801795])\nprint(type(train_traits.loc[101801795]))'''\n\n'''print(torch.tensor(train_traits.loc[101801795].values))'''\n\n# print(data_max, data_min)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T16:19:07.873343Z","iopub.execute_input":"2024-08-10T16:19:07.873637Z","iopub.status.idle":"2024-08-10T16:19:07.879857Z","shell.execute_reply.started":"2024-08-10T16:19:07.873612Z","shell.execute_reply":"2024-08-10T16:19:07.878928Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'print(torch.tensor(train_traits.loc[101801795].values))'"},"metadata":{}}]},{"cell_type":"code","source":"class CustomDataSet(Dataset):\n    def __init__(self, root_dir, indices, label_mapping, target_mapping, transform = None):\n        self.root_dir = root_dir\n        self.indices = indices\n        self.transform = transform\n        self.image_paths = []\n        self.targets = []\n        self.labels = []\n        \n        for idx in indices:\n            self.image_paths.append(os.path.join(root_dir, str(idx) + \".jpeg\"))\n            target = self.get_target_from_filename(idx, target_mapping)\n            self.targets.append(target)\n            label = self.get_label_from_filename(idx, label_mapping)\n            self.labels.append(label)\n                \n    def get_target_from_filename(self, idx, target_mapping):\n        target = target_mapping.loc[idx].values\n        return torch.tensor(target).float()\n    \n    def get_label_from_filename(self, idx, label_mapping):\n        target = label_mapping.loc[idx].values\n        return torch.tensor(target).float()\n        \n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = Image.open(img_path)\n        target = self.targets[idx]\n        label = self.labels[idx]\n \n        if self.transform:\n            image = self.transform(image)\n\n        return image, label, target","metadata":{"execution":{"iopub.status.busy":"2024-08-10T16:19:07.880872Z","iopub.execute_input":"2024-08-10T16:19:07.881148Z","iopub.status.idle":"2024-08-10T16:19:07.891587Z","shell.execute_reply.started":"2024-08-10T16:19:07.881126Z","shell.execute_reply":"2024-08-10T16:19:07.890704Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.ColorJitter(brightness=(0.9, 1.1), contrast=(0.9, 1.1), saturation=(0.9, 1.1)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\nvalidation_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\n\ntrainset = CustomDataSet('/kaggle/input/cs-480-2024-spring/data/train_images/', train_data_normalized.index.tolist(), train_data_normalized,\n                          train_traits_normalized, transform=train_transform)\nvalidationset = CustomDataSet('/kaggle/input/cs-480-2024-spring/data/train_images/', validation_data_normalized.index.tolist(), validation_data_normalized,\n                               validation_traits_normalized, transform=validation_transform)\n\nbatch_size = 32\n\ntrainloader = DataLoader(trainset, batch_size = batch_size, shuffle=True)\nvalidationloader = DataLoader(validationset, batch_size = batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T16:19:07.892639Z","iopub.execute_input":"2024-08-10T16:19:07.893045Z","iopub.status.idle":"2024-08-10T16:19:18.862794Z","shell.execute_reply.started":"2024-08-10T16:19:07.893016Z","shell.execute_reply":"2024-08-10T16:19:18.861803Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"'''for i, sample in enumerate(trainloader):\n    image, label, target = sample[0], sample[1], sample[2]\n    print(image, label, target)\n    break'''\n\n# print(len(trainloader))","metadata":{"execution":{"iopub.status.busy":"2024-08-10T16:19:18.864033Z","iopub.execute_input":"2024-08-10T16:19:18.864405Z","iopub.status.idle":"2024-08-10T16:19:18.870610Z","shell.execute_reply.started":"2024-08-10T16:19:18.864374Z","shell.execute_reply":"2024-08-10T16:19:18.869611Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'for i, sample in enumerate(trainloader):\\n    image, label, target = sample[0], sample[1], sample[2]\\n    print(image, label, target)\\n    break'"},"metadata":{}}]},{"cell_type":"markdown","source":"# CNN","metadata":{}},{"cell_type":"code","source":"device = (\n    \"cuda\"\n    if torch.cuda.is_available()\n    else \"mps\"\n    if torch.backends.mps.is_available()\n    else \"cpu\"\n)\nprint(f\"Using {device} device\")","metadata":{"execution":{"iopub.status.busy":"2024-08-10T16:19:18.874821Z","iopub.execute_input":"2024-08-10T16:19:18.875143Z","iopub.status.idle":"2024-08-10T16:19:18.939337Z","shell.execute_reply.started":"2024-08-10T16:19:18.875117Z","shell.execute_reply":"2024-08-10T16:19:18.938235Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Using cuda device\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"'''weights = ResNet34_Weights.DEFAULT\npreprocess = weights.transforms()\n\nprint(preprocess)'''\n\n# print(inception_v3(weights=Inception_V3_Weights.DEFAULT))","metadata":{"execution":{"iopub.status.busy":"2024-08-10T16:19:18.940442Z","iopub.execute_input":"2024-08-10T16:19:18.940720Z","iopub.status.idle":"2024-08-10T16:19:18.951274Z","shell.execute_reply.started":"2024-08-10T16:19:18.940697Z","shell.execute_reply":"2024-08-10T16:19:18.950301Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'weights = ResNet34_Weights.DEFAULT\\npreprocess = weights.transforms()\\n\\nprint(preprocess)'"},"metadata":{}}]},{"cell_type":"code","source":"class CNNBranch(nn.Module):\n    def __init__(self):\n        super(CNNBranch, self).__init__()\n        \n        self.pretrained = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n        \n        for param in self.pretrained.parameters():\n            param.requires_grad = False\n            \n        # Unfreeze all BatchNorm layers\n        for module in self.pretrained.modules():\n            if isinstance(module, nn.BatchNorm2d):\n                for param in module.parameters():\n                    param.requires_grad = True\n        \n        fc_inputs = self.pretrained.fc.in_features\n        self.pretrained.fc = nn.Sequential(\n            nn.Linear(fc_inputs, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n        )\n    \n    def forward(self, x):\n        x = self.pretrained(x)\n        return x\n    \n\nclass AncillaryBranch(nn.Module):\n    def __init__(self):\n        super(AncillaryBranch, self).__init__()\n        \n        self.ancillary = nn.Sequential(\n            nn.Linear(163, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(1024, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(1024, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n        )\n    \n    def forward(self, x):\n        x = self.ancillary(x)\n        return x\n\n\nclass CombinedModel(nn.Module):\n    def __init__(self):\n        super(CombinedModel, self).__init__()\n        \n        self.cnn_branch = CNNBranch()\n        self.ancillary_branch = AncillaryBranch()\n        \n        self.combined_regressor = nn.Sequential(\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 6)\n        )\n    \n    def forward(self, image, ancillary):\n        image_features = self.cnn_branch(image)\n        ancillary_features = self.ancillary_branch(ancillary)\n        \n        combined_features = torch.cat((image_features, ancillary_features), dim=1)\n        \n        x = self.combined_regressor(combined_features) \n        return x","metadata":{"execution":{"iopub.status.busy":"2024-08-10T16:19:18.952425Z","iopub.execute_input":"2024-08-10T16:19:18.952691Z","iopub.status.idle":"2024-08-10T16:19:18.968303Z","shell.execute_reply.started":"2024-08-10T16:19:18.952669Z","shell.execute_reply":"2024-08-10T16:19:18.967434Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"model = CombinedModel()\noptimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\ncriterion = nn.MSELoss()\nmodel.to(device)\nprint(\"Model Created\")","metadata":{"execution":{"iopub.status.busy":"2024-08-10T16:19:18.969348Z","iopub.execute_input":"2024-08-10T16:19:18.969904Z","iopub.status.idle":"2024-08-10T16:19:20.643795Z","shell.execute_reply.started":"2024-08-10T16:19:18.969882Z","shell.execute_reply":"2024-08-10T16:19:20.642860Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 156MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Model Created\n","output_type":"stream"}]},{"cell_type":"code","source":"def train(model, device, train_loader, criterion, optimizer, epoch):\n    loss_fn = criterion\n    model.train()\n    train_loss_total = 0\n    for batch_idx, (data, label, target) in enumerate(train_loader):\n        data, label, target = data.to(device), label.to(device),target.to(device)\n        optimizer.zero_grad()\n        output = model(data, label)\n        loss = loss_fn(output, target)\n        \n        '''reg_loss = 0\n        for param in model.parameters():\n            reg_loss += torch.norm(param, 1)\n        loss += 0.3 * reg_loss'''\n        \n        loss.backward()\n        train_loss_total += loss.item()\n        optimizer.step()\n        \n        if (batch_idx + 1) % 100 == 0:\n            print('[{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                (batch_idx + 1) * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()))\n\n    print(\"Total training loss: \", train_loss_total)\n    print(\"Number of data points: \", len(train_loader.dataset))\n    train_loss = train_loss_total / (len(train_loader.dataset))\n\n    print('Training set Average loss: {}'.format(train_loss))\n    return train_loss\n\n\ndef validate(model, device, validate_loader, criterion, epoch):\n    loss_fn = criterion\n    model.eval()\n    validate_loss_total = 0\n    with torch.no_grad():\n        for batch_idx, (data, label, target) in enumerate(validate_loader):\n            data, label, target = data.to(device), label.to(device),target.to(device)\n            output = model(data, label)\n            loss = loss_fn(output, target)\n            validate_loss_total += loss.item()\n        \n        print(\"Total validation loss: \", validate_loss_total)\n        print(\"Number of data points: \", len(validate_loader.dataset))\n        validate_loss = validate_loss_total / len(validate_loader.dataset)\n        print('Validation set Average loss: ', validate_loss)\n        return validate_loss","metadata":{"execution":{"iopub.status.busy":"2024-08-10T16:19:20.644912Z","iopub.execute_input":"2024-08-10T16:19:20.645224Z","iopub.status.idle":"2024-08-10T16:19:20.656749Z","shell.execute_reply.started":"2024-08-10T16:19:20.645199Z","shell.execute_reply":"2024-08-10T16:19:20.655807Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"num_epochs = 12\ntraining_loss = [0 for _ in range(num_epochs)]\nvalidation_loss = [0 for _ in range(num_epochs)]\nbest_val_loss = 1000000000\noverfit_count = 2\nfor epoch in range(1, num_epochs + 1):\n    print(\"Epoch: \", epoch)\n    print(\"---------------------------------------------\")\n\n    train_loss = train(model, device, trainloader, criterion, optimizer, epoch)\n    val_loss = validate(model, device, validationloader, criterion, epoch)\n    \n    training_loss[epoch - 1] = train_loss\n    validation_loss[epoch - 1] = val_loss\n    \n    if val_loss < best_val_loss:\n        print(\"Best so far is epoch \", epoch)\n        best_val_loss = val_loss\n        overfit_count = 2\n        torch.save(model.state_dict(), 'best_weights.pth')\n    else:\n        overfit_count -= 1\n    \n    if overfit_count == 0:\n        print(\"---------------------------------------------\")\n        print('Early stopping')\n        print(\"---------------------------------------------\")\n        break\n    \n    if epoch % 3 == 0:\n        torch.save(model.state_dict(), 'epoch{}.pth'.format(epoch))\n        print(f'Model saved at epoch {epoch}')\n        \n\n    print(\"---------------------------------------------\")\n\nprint('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2024-08-10T18:19:30.903903Z","iopub.execute_input":"2024-08-10T18:19:30.904616Z","iopub.status.idle":"2024-08-10T18:58:17.730374Z","shell.execute_reply.started":"2024-08-10T18:19:30.904583Z","shell.execute_reply":"2024-08-10T18:58:17.729283Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Epoch:  1\n---------------------------------------------\n[3200/39027 (8%)]\tLoss: 0.010411\n[6400/39027 (16%)]\tLoss: 0.009596\n[9600/39027 (25%)]\tLoss: 0.011951\n[12800/39027 (33%)]\tLoss: 0.021961\n[16000/39027 (41%)]\tLoss: 0.015487\n[19200/39027 (49%)]\tLoss: 0.010063\n[22400/39027 (57%)]\tLoss: 0.014738\n[25600/39027 (65%)]\tLoss: 0.020903\n[28800/39027 (74%)]\tLoss: 0.015643\n[32000/39027 (82%)]\tLoss: 0.018145\n[35200/39027 (90%)]\tLoss: 0.012474\n[38400/39027 (98%)]\tLoss: 0.016632\nTotal training loss:  20.15190584771335\nNumber of data points:  39027\nTraining set Average loss: 0.0005163580559026661\nTotal validation loss:  2.131046287715435\nNumber of data points:  4336\nValidation set Average loss:  0.000491477464879021\nBest so far is epoch  1\n---------------------------------------------\nEpoch:  2\n---------------------------------------------\n[3200/39027 (8%)]\tLoss: 0.011474\n[6400/39027 (16%)]\tLoss: 0.017293\n[9600/39027 (25%)]\tLoss: 0.019680\n[12800/39027 (33%)]\tLoss: 0.017984\n[16000/39027 (41%)]\tLoss: 0.020735\n[19200/39027 (49%)]\tLoss: 0.014953\n[22400/39027 (57%)]\tLoss: 0.018294\n[25600/39027 (65%)]\tLoss: 0.018546\n[28800/39027 (74%)]\tLoss: 0.010401\n[32000/39027 (82%)]\tLoss: 0.025599\n[35200/39027 (90%)]\tLoss: 0.028070\n[38400/39027 (98%)]\tLoss: 0.010054\nTotal training loss:  19.988962438888848\nNumber of data points:  39027\nTraining set Average loss: 0.0005121829102644028\nTotal validation loss:  2.11888384912163\nNumber of data points:  4336\nValidation set Average loss:  0.0004886724744284203\nBest so far is epoch  2\n---------------------------------------------\nEpoch:  3\n---------------------------------------------\n[3200/39027 (8%)]\tLoss: 0.012068\n[6400/39027 (16%)]\tLoss: 0.018373\n[9600/39027 (25%)]\tLoss: 0.012427\n[12800/39027 (33%)]\tLoss: 0.017345\n[16000/39027 (41%)]\tLoss: 0.019363\n[19200/39027 (49%)]\tLoss: 0.013463\n[22400/39027 (57%)]\tLoss: 0.014803\n[25600/39027 (65%)]\tLoss: 0.015841\n[28800/39027 (74%)]\tLoss: 0.019327\n[32000/39027 (82%)]\tLoss: 0.009654\n[35200/39027 (90%)]\tLoss: 0.012411\n[38400/39027 (98%)]\tLoss: 0.011871\nTotal training loss:  19.87461831094697\nNumber of data points:  39027\nTraining set Average loss: 0.0005092530379211052\nTotal validation loss:  2.120429402217269\nNumber of data points:  4336\nValidation set Average loss:  0.0004890289211755694\nModel saved at epoch 3\n---------------------------------------------\nEpoch:  4\n---------------------------------------------\n[3200/39027 (8%)]\tLoss: 0.012373\n[6400/39027 (16%)]\tLoss: 0.022682\n[9600/39027 (25%)]\tLoss: 0.017386\n[12800/39027 (33%)]\tLoss: 0.016255\n[16000/39027 (41%)]\tLoss: 0.010975\n[19200/39027 (49%)]\tLoss: 0.013868\n[22400/39027 (57%)]\tLoss: 0.012188\n[25600/39027 (65%)]\tLoss: 0.013358\n[28800/39027 (74%)]\tLoss: 0.013200\n[32000/39027 (82%)]\tLoss: 0.014627\n[35200/39027 (90%)]\tLoss: 0.024151\n[38400/39027 (98%)]\tLoss: 0.016117\nTotal training loss:  19.782172969542444\nNumber of data points:  39027\nTraining set Average loss: 0.000506884284458002\nTotal validation loss:  2.1193986795842648\nNumber of data points:  4336\nValidation set Average loss:  0.0004887912083912049\n---------------------------------------------\nEarly stopping\n---------------------------------------------\nFinished Training\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Fine Tuning","metadata":{}},{"cell_type":"markdown","source":"# Evaluate","metadata":{}},{"cell_type":"code","source":"PATH = '/kaggle/working/best_weights.pth'\nmodel.load_state_dict(torch.load(PATH))","metadata":{"execution":{"iopub.status.busy":"2024-08-10T19:01:10.036148Z","iopub.execute_input":"2024-08-10T19:01:10.036976Z","iopub.status.idle":"2024-08-10T19:01:10.157114Z","shell.execute_reply.started":"2024-08-10T19:01:10.036935Z","shell.execute_reply":"2024-08-10T19:01:10.156175Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"def r2score(model, device, dataloader):\n    predictions = []\n    targets = []\n    model.eval()\n    with torch.no_grad():\n        for batch_idx, (data, label, target) in enumerate(dataloader):\n            data, label, target = data.to(device), label.to(device), target.to(device)\n            output = model(data, label)\n            predictions.extend(output.cpu().numpy())\n            targets.extend(target.cpu().numpy())\n        \n        targets = np.array(targets)\n        predictions = np.array(predictions)\n\n        scores = []\n        for i in range(6):\n            r2 = r2_score(targets[:, i], predictions[:, i])\n            scores.append(r2)\n            \n        print(scores)\n        return np.mean(scores)\n            ","metadata":{"execution":{"iopub.status.busy":"2024-08-10T18:14:46.233738Z","iopub.execute_input":"2024-08-10T18:14:46.234100Z","iopub.status.idle":"2024-08-10T18:14:46.241820Z","shell.execute_reply.started":"2024-08-10T18:14:46.234053Z","shell.execute_reply":"2024-08-10T18:14:46.240968Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"r2score(model, device, validationloader)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T19:01:11.716860Z","iopub.execute_input":"2024-08-10T19:01:11.717653Z","iopub.status.idle":"2024-08-10T19:01:38.002419Z","shell.execute_reply.started":"2024-08-10T19:01:11.717620Z","shell.execute_reply":"2024-08-10T19:01:38.001431Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"[0.2018676851202742, 0.27785953679887765, 0.3997037344787102, 0.18729556012737847, 0.1650591843464123, 0.2580226862287671]\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"0.24830139785006997"},"metadata":{}}]},{"cell_type":"markdown","source":"# Predict","metadata":{}},{"cell_type":"code","source":"class TestImageSet(Dataset):\n    def __init__(self, root_dir, indices, label_mapping, target_mapping, transform = None):\n        self.root_dir = root_dir\n        self.indices = indices\n        self.transform = transform\n        self.image_paths = []\n        self.targets = []\n        self.labels = []\n        \n        for idx in indices:\n            self.image_paths.append(os.path.join(root_dir, str(idx) + \".jpeg\"))\n            target = self.get_target_from_filename(idx, target_mapping)\n            self.targets.append(target)\n            label = self.get_label_from_filename(idx, label_mapping)\n            self.labels.append(label)\n                \n    def get_target_from_filename(self, idx, target_mapping):\n        return int(target_mapping.loc[idx].values[0])\n    \n    def get_label_from_filename(self, idx, label_mapping):\n        target = label_mapping.loc[idx].values\n        return torch.tensor(target).float()\n        \n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = Image.open(img_path)\n        target = self.targets[idx]\n        label = self.labels[idx]\n \n        if self.transform:\n            image = self.transform(image)\n\n        return image, label, target","metadata":{"execution":{"iopub.status.busy":"2024-08-10T18:15:11.641450Z","iopub.execute_input":"2024-08-10T18:15:11.641791Z","iopub.status.idle":"2024-08-10T18:15:11.651513Z","shell.execute_reply.started":"2024-08-10T18:15:11.641765Z","shell.execute_reply":"2024-08-10T18:15:11.650773Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/cs-480-2024-spring/data/test.csv\")\ntest_data = test_data.set_index('id')\n\ntest_data_normalized = (test_data - data_min) / (data_max - data_min)\n\n# Mapping for IDs\ntest_data_index = pd.DataFrame(index = test_data.index)\ntest_data_index['id'] = test_data.index\ntest_data_index['id'] = test_data_index['id'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T18:15:11.652496Z","iopub.execute_input":"2024-08-10T18:15:11.652789Z","iopub.status.idle":"2024-08-10T18:15:11.890363Z","shell.execute_reply.started":"2024-08-10T18:15:11.652757Z","shell.execute_reply":"2024-08-10T18:15:11.889394Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"'''print(test_data_index['id'].nunique())\nprint(test_data.index.nunique())\nprint(type(test_data.index))'''","metadata":{"execution":{"iopub.status.busy":"2024-08-10T18:15:11.891539Z","iopub.execute_input":"2024-08-10T18:15:11.891827Z","iopub.status.idle":"2024-08-10T18:15:11.897263Z","shell.execute_reply.started":"2024-08-10T18:15:11.891801Z","shell.execute_reply":"2024-08-10T18:15:11.896405Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"\"print(test_data_index['id'].nunique())\\nprint(test_data.index.nunique())\\nprint(type(test_data.index))\""},"metadata":{}}]},{"cell_type":"code","source":"test_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\n\ntestset = TestImageSet('/kaggle/input/cs-480-2024-spring/data/test_images/', test_data.index.tolist(), label_mapping = test_data_normalized,\n                               target_mapping = test_data_index, transform=test_transform)\n\nbatch_size = 1\n\ntestloader = DataLoader(testset, batch_size = batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T18:15:11.898510Z","iopub.execute_input":"2024-08-10T18:15:11.899129Z","iopub.status.idle":"2024-08-10T18:15:13.353172Z","shell.execute_reply.started":"2024-08-10T18:15:11.899101Z","shell.execute_reply":"2024-08-10T18:15:13.352185Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"columns = ['id', 'X4', 'X11', 'X18', 'X26', 'X50', 'X3112']\ndef predict(model, device, test_loader):\n    model.eval()\n    predictions = []\n    with torch.no_grad():\n        for data, label, target in test_loader:\n            data, label, target = data.to(device), label.to(device), target.to(device)\n            output = model(data, label)\n            output = inverse_transformation(output.cpu().numpy()[0])\n            target = int(target.cpu().numpy()[0])\n            \n            new_row = pd.Series([target] + output.tolist(), index=columns)\n            predictions.append(new_row)\n            \n    return predictions","metadata":{"execution":{"iopub.status.busy":"2024-08-10T18:15:13.354433Z","iopub.execute_input":"2024-08-10T18:15:13.354784Z","iopub.status.idle":"2024-08-10T18:15:13.362538Z","shell.execute_reply.started":"2024-08-10T18:15:13.354753Z","shell.execute_reply":"2024-08-10T18:15:13.361689Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"predictions = predict(model, device, testloader)\ndf = pd.DataFrame(predictions)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T19:02:25.858056Z","iopub.execute_input":"2024-08-10T19:02:25.858922Z","iopub.status.idle":"2024-08-10T19:03:44.811614Z","shell.execute_reply.started":"2024-08-10T19:02:25.858890Z","shell.execute_reply":"2024-08-10T19:03:44.810584Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"'''print(df['id'].nunique())\nprint(df.shape)\n\nprint(df['id'].duplicated())'''\n# print(df.head())","metadata":{"execution":{"iopub.status.busy":"2024-08-10T18:16:48.658791Z","iopub.execute_input":"2024-08-10T18:16:48.659083Z","iopub.status.idle":"2024-08-10T18:16:48.664764Z","shell.execute_reply.started":"2024-08-10T18:16:48.659040Z","shell.execute_reply":"2024-08-10T18:16:48.663828Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"\"print(df['id'].nunique())\\nprint(df.shape)\\n\\nprint(df['id'].duplicated())\""},"metadata":{}}]},{"cell_type":"code","source":"df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T19:04:15.627743Z","iopub.execute_input":"2024-08-10T19:04:15.628371Z","iopub.status.idle":"2024-08-10T19:04:15.713835Z","shell.execute_reply.started":"2024-08-10T19:04:15.628340Z","shell.execute_reply":"2024-08-10T19:04:15.713111Z"},"trusted":true},"execution_count":37,"outputs":[]}]}